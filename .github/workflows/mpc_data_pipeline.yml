name: Asteroid Data Update - Weekly (Minor Planet Center)

on:
  schedule:
    - cron: "0 0 * * 0"  # 00:00 UTC Sunday each week
  workflow_dispatch:

permissions:
  contents: 'read'

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

jobs:
  fetch-and-store-data:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4.1.7

      - name: Set up Python
        uses: actions/setup-python@v5.1.0
        with:
          python-version: "3.10"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas boto3

      - name: Run data fetcher
        env:
          # Required by your script:
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
          R2_JSON_KEY: asteroids.json
          # ---- Output Settings ----
          OUT_CSV_NAME: asteroids.csv
          OUT_JSON_NAME: asteroids.json     
          
          # Test-mode knobs:
          MAX_ROWS_INGEST:   "0"
          SKIP_GCS_EXPORT:   "0"
          # (optional) make batches smaller for a snappier test:
          UPSERT_BATCH_SIZE: "500"
                
        run: |
          python backend/datapipe/mpc_data_fetcher.py
